# Inference config for auto image captioning

# Model to use: either Salesforce/blip-image-captioning-large or nlpconnect/vit-gpt2-image-captioning
model_name: "nlpconnect/vit-gpt2-image-captioning"

# Folder containing images (relative to train folder)
dataset_dir: "./train/images"

# Folder where captions_filled.json will be saved
output_dir: "./train/outputs"
